{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input is a Pandas table of ax, ay, az, gx, gy, gz over time\n",
    "## Output is a np table of ax, ay, az, gx, gy, gz and selected features\n",
    "import numpy as np\n",
    "import pickle\n",
    "#from scipy import stats, fft, fftpack\n",
    "\n",
    "def raw_to_abt_np(dataframe):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    #sensor_data = dataframe.to_numpy()\n",
    "    print(sensor_data.shape)\n",
    "    #want to see (# of samples,6)\n",
    "    \n",
    "    means = np.mean(sensor_data, axis=0)\n",
    "    ranges = np.ptp(sensor_data, axis = 0)\n",
    "    stds = np.std(sensor_data, axis=0)\n",
    "    moment_3 = stats.moment(sensor_data, moment=3, axis=0)\n",
    "    \n",
    "    dcts = fftpack.dct(sensor_data, axis=0)\n",
    "    sorted_dcts = np.sort(dcts, axis=0)\n",
    "    max_dcts = sorted_dcts[0]\n",
    "    second_max_dcts = sorted_dcts[1]\n",
    "    \n",
    "    ffts = fft(sensor_data, axis=0)\n",
    "    sorted_ffts = np.sort(ffts,axis=0)\n",
    "    max_ffts = sorted_ffts[0]\n",
    "    second_max_ffts = sorted_ffts[1]\n",
    "    \n",
    "    to_be_stacked = (means, ranges, stds, moment_3, max_dcts, second_max_dcts, \n",
    "                    max_ffts, second_max_ffts)\n",
    "    \n",
    "    abt_table = np.vstack(to_be_stacked)\n",
    "    \n",
    "    return abt_table\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output random digit between 0-9\n",
    "\n",
    "from random import randint\n",
    "from random import seed\n",
    "import os\n",
    "\n",
    "seed()\n",
    "dataset_filename = 'digits_data.p'\n",
    "def generate_randint():\n",
    "    while True:\n",
    "        yield randint(0,9)\n",
    "\n",
    "def read_dataset():\n",
    "    \n",
    "    if not os.path.isfile(dataset_filename):\n",
    "        print('{} not found'.format(dataset_filename))\n",
    "        with open(dataset_filename, 'wb+') as f:\n",
    "            pickle.dump(f,{})\n",
    "            \n",
    "    with open(dataset_filename,'rb') as f:\n",
    "        try:\n",
    "            digits_data = pickle.load(f)\n",
    "        except EOFError:\n",
    "            print('Empty file')\n",
    "            digits_data = {'samples':[],'labels':[]}\n",
    "            \n",
    "    return digits_data\n",
    "\n",
    "def write_dataset(dataset):\n",
    "    with open(dataset_filename,'wb') as f:\n",
    "        pickle.dump(dataset, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "\n",
    "#function to record data to create dataset\n",
    "def record_training_data():\n",
    "    '''\n",
    "    tell user to write down digit\n",
    "    record raw values\n",
    "    perform feature extraction\n",
    "    pickle the data\n",
    "    '''\n",
    "    digits_data = read_dataset()\n",
    "    \n",
    "    samples = digits_data['samples']\n",
    "    labels = digits_data['labels']\n",
    "    \n",
    "    random_integer = generate_randint()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        integer = next(random_integer)\n",
    "        print('Write {}'.format(integer))\n",
    "        \n",
    "        samples.append(input('Press any key'))\n",
    "        labels.append(integer)\n",
    "        \n",
    "    digits_data['labels'] = labels\n",
    "    digits_data['samples'] = samples\n",
    "    \n",
    "    print(digits_data)\n",
    "    input('Press enter to approve of appending to training dataset')\n",
    "    write_dataset(digits_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 4\n",
      "Press any key\n",
      "Write 5\n",
      "Press any key\n",
      "Write 4\n",
      "Press any key\n",
      "Write 6\n",
      "Press any key\n",
      "Write 3\n",
      "Press any key\n",
      "{'samples': ['1', '2', '3', '4', '5', '8', '8', '7', '9', '6', '', '', '', '', ''], 'labels': [2, 9, 1, 5, 2, 8, 8, 7, 9, 6, 4, 5, 4, 6, 3]}\n",
      "Press enter to approve of appending to training dataset\n"
     ]
    }
   ],
   "source": [
    "record_training_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samples': ['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '8',\n",
       "  '8',\n",
       "  '7',\n",
       "  '9',\n",
       "  '6',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " 'labels': [2, 9, 1, 5, 2, 8, 8, 7, 9, 6, 4, 5, 4, 6, 3]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
